---
title: Many models, same data
author: Lydia English and Gina Nichols
date: '2020-04-22'
slug: many-models
categories: 
  - Weeds
  - Model selection
tags: 
  - r
  - Grad School
subtitle: ''
summary: ''
authors: []
lastmod: '2020-04-23T14:27:24-05:00'
draft: false
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---



<p>This post explores the often agonizing decision-making process behind model selection. At least as an indecisive non-statistician I find the process to be slightly agaonizing. Let’s just emphasize something again - I’m not a statistician and am continually learning! This post will probably be most helpful for other non-statisticians although I’m happy to take constructive feedback from anyone.</p>
<p>I will be using a real-life example, meaning this is an actual decision process that Gina Nichols and I waded through as we prepped a manuscript. The hope is that others who may struggle with the same sorts of basic stats decisions can take solace in this process.</p>
<p>Gina and I are using data from <a href="/project/pfiweeds/">this project</a>. In very breif terms we’re interested in the effect of cover crops on the weed seedbank of corn/soybean cropping systems. While cover crops are oft cited as a practice than can help decrease erosion or nutrient export, we are curious if using cover crops can help decrease the weed seedbank. This is especially important because of the increasing prevalence of herbicide resistent weeds across the Midwest (and beyond).</p>
<p>The data can be accessed from Gina Nichol’s Github repository like so:</p>
<p><code>remotes::install_github("vanichols/PFIweeds2020")</code></p>
<p>The raw data are in <code>pfi_ghobsraw</code>. These are observations from soil which Gina incubated in a greenhouse to grow weeds. We don’t need to clean the data very much, but we will do a couple steps to consolidate observations.</p>
<p>A couple other notes on the experimental layout:</p>
<ul>
<li><p>There are four <code>site_sys</code>, which encompass three different farms and two different cropping systems</p>
<ul>
<li>Boyd Grain</li>
<li>Boyd Silage</li>
<li>Funcke Grain</li>
<li>Stout Grain</li>
</ul>
<p><em>FYI: Grain systems employ a two year rotation of corn and soybeans and sell both crops off as feed grain, ethanol grain, etc. The silage system also has a 2 year rotation of corn and soybeans, but in the corn year the crop is harvested earlier (while it’s still green) and sold as silage (fermented cattle feed)</em></p></li>
<li><p>There are two cover crop treatments <code>cc_trt</code> = <code>none</code> and <code>cc_rye</code>= <code>rye</code></p></li>
<li><p>There are 4-5 blocks per treatment, which will our random effect.</p></li>
</ul>
<pre class="r"><code>library(PFIweeds2020)
data(&quot;pfi_ghobsraw&quot;)

# Quick data cleaning
dat &lt;- 
  pfi_ghobsraw %&gt;% 
  dplyr::mutate_if(is.numeric, tidyr::replace_na, 0) %&gt;%
  dplyr::group_by(site_name, field, sys_trt, cc_trt, rep, blockID) %&gt;%
  dplyr::summarise_if(is.numeric, sum) %&gt;%
  dplyr::ungroup() %&gt;%
# Sum all seeds by species  
  dplyr::mutate(totseeds = rowSums(.[, 7:24])) %&gt;%
  tidyr::unite(site_name, sys_trt, col = &quot;site_sys&quot;, remove = T) %&gt;% 
  select(-field, -rep, -c(AMATU:UB)) %&gt;%
  mutate(cc_trt = recode(cc_trt,         
                          no = &quot;none&quot;,
                          rye = &quot;cc_rye&quot;))
head(dat)</code></pre>
<pre><code>## # A tibble: 6 x 4
##   site_sys   cc_trt blockID totseeds
##   &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;      &lt;dbl&gt;
## 1 Boyd_grain none   B42_1         34
## 2 Boyd_grain none   B42_2         12
## 3 Boyd_grain none   B42_3          9
## 4 Boyd_grain none   B42_4          7
## 5 Boyd_grain none   B42_5         17
## 6 Boyd_grain cc_rye B42_1        116</code></pre>
<p>We are interested in <code>totseeds</code> (total seeds) as a response variable, which is an integer value. In all of our mixed models our fixed effects are <code>site_sys</code> and <code>cc_trt</code> and our random effect is <code>blockID</code>.</p>
<p>But before we get to modeling, let’s just quickly look at the data and see what we are working with.</p>
<p><img src="/post/weed_model_selection/index_files/figure-html/unnamed-chunk-2-1.png" width="672" />
There is one point that is much higher than the rest, in the <code>Funcke_grain</code> cover crop treatment, which may be a little cause for concern…we’re going to make another dataset without it.</p>
<pre class="r"><code>dat2 &lt;- dat %&gt;%
  filter(totseeds &lt; 700)</code></pre>
<p>Let’s also plot the distribution of totseeds. It is pretty skewed. If we log-tranform the raw data we get a much nicer distribution and our large values are much less far apart than are small values.</p>
<p><img src="/post/weed_model_selection/index_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Ok now it’s time to start fitting out models. Given the graphs above, our first thought was to run a lmer with a log-transformed response.</p>
<p>(Here we are also examining whether there is any interaction between <code>site_sys</code> and <code>cc_trt</code>, and looks like there is. We are therefore going to keep the interaction)</p>
<pre class="r"><code>m1 &lt;- lmer(log(totseeds) ~ site_sys * cc_trt + (1|blockID), data = dat2)
m2 &lt;- lmer(log(totseeds) ~ site_sys + cc_trt + (1|blockID), data = dat2)

anova(m1, m2) # keep interaction</code></pre>
<pre><code>## Data: dat2
## Models:
## m2: log(totseeds) ~ site_sys + cc_trt + (1 | blockID)
## m1: log(totseeds) ~ site_sys * cc_trt + (1 | blockID)
##    npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)  
## m2    7 117.40 130.04 -51.698  103.397                       
## m1   10 115.13 133.20 -47.566   95.132 8.2643  3    0.04085 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Before we dive into the summary values and statistical reporting lets check out our diagnostic plots:</p>
<pre class="r"><code>resid_panel(m1)</code></pre>
<p><img src="/post/weed_model_selection/index_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>This doesn’t look bad, but perhaps it could look better…</p>
<p>To stick within the normal-distribution framework we could also try another transformation. The square-root transformation can also work for count data.</p>
<pre class="r"><code>dat %&gt;%
  ggplot(aes(sqrt(totseeds)))+
  geom_histogram(binwidth = 1, fill = &quot;white&quot;, color = &quot;black&quot;)+
  ggtitle(&quot;Sqrt-transformed Data&quot;)+
  theme(plot.title.position = &quot;plot&quot;)</code></pre>
<p><img src="/post/weed_model_selection/index_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>The data still look a little skewed, but that’s ok…</p>
<pre class="r"><code>m1b &lt;- lmer(sqrt(totseeds) ~ site_sys * cc_trt + (1|blockID), dat2)
resid_panel(m1b)</code></pre>
<p><img src="/post/weed_model_selection/index_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>These diagnostic plots look pretty similar, although the square root transformation might be a little better. The problem with the square root transformation is that it renders the data pretty uninterpretable.</p>
<p>Since we are working with count data, however, we have other options in our stats toolbox - generalized linear models. The natural first option is a Poisson distribution with a log link function:</p>
<pre class="r"><code>p1a &lt;- glmer(totseeds ~ site_sys*cc_trt + (1|blockID), data = dat2, 
            family = poisson(link = &quot;log&quot;))</code></pre>
<p>This model converged, awesome! But we should always check for overdispersion in our Poisson models, which is when the variance &gt;&gt; mean. We are using the <a href="https://easystats.github.io/performance/">performance</a> package for this since it makes checking for overdispersion really easy.</p>
<pre class="r"><code>performance::check_overdispersion(p1a) </code></pre>
<pre><code>## # Overdispersion test
## 
##        dispersion ratio =   8.001
##   Pearson&#39;s Chi-Squared = 288.047
##                 p-value = &lt; 0.001</code></pre>
<pre><code>## Overdispersion detected.</code></pre>
<p>Just as an aside, you can also calcuate dispersion by hand by like:</p>
<pre class="r"><code>1 - pchisq(deviance(p1a), df.residual(p1a)) </code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code>r &lt;- resid(p1a,type=&quot;pearson&quot;)
1-pchisq(sum(r^2),df.residual(p1a))</code></pre>
<pre><code>## [1] 0</code></pre>
<p>Either way our p-value is very close to 0, so it looks like our data are overdispersed.</p>
<p>Now we have two options if we want to continue down the glmer path. We could:</p>
<ol style="list-style-type: decimal">
<li><p>Add an observation-level random effect to our Poisson model</p></li>
<li><p>Switch to a negative binomial model</p></li>
</ol>
<p>Let’s start with option 1 and add an oberservation-level random effect.</p>
<pre class="r"><code>dat2 &lt;- 
  dat2 %&gt;%
  mutate(obs_id = paste(&quot;obs&quot;, 1:45, sep = &quot;_&quot;))

p1b &lt;- glmer(totseeds ~ site_sys*cc_trt + (1|blockID) + (1|obs_id), data = dat2, 
            family = poisson(link = &quot;log&quot;))</code></pre>
<pre class="r"><code>performance::check_overdispersion(p1b)</code></pre>
<pre><code>## # Overdispersion test
## 
##        dispersion ratio = 0.145
##   Pearson&#39;s Chi-Squared = 5.065
##                 p-value =     1</code></pre>
<pre><code>## No overdispersion detected.</code></pre>
<pre class="r"><code># or 

1 - pchisq(deviance(p1b), df.residual(p1b)) </code></pre>
<pre><code>## [1] 1</code></pre>
<pre class="r"><code>r &lt;- resid(p1b,type=&quot;pearson&quot;)
1-pchisq(sum(r^2),df.residual(p1b))</code></pre>
<pre><code>## [1] 1</code></pre>
<p>Adding our observation-level random effect fixed out overdispersion problem. Great!</p>
<p>Let’s also try option 2 and fit the data to a negative-binomial model</p>
<pre class="r"><code># option 2, negative binomial....
g1a &lt;- glmer.nb(totseeds ~ site_sys*cc_trt + (1|blockID), data = dat2)</code></pre>
<p>Also converges, great!</p>
<p>Let’s now compare our summary values:</p>
<pre class="r"><code>summary(p1b)</code></pre>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: poisson  ( log )
## Formula: totseeds ~ site_sys * cc_trt + (1 | blockID) + (1 | obs_id)
##    Data: dat2
## 
##      AIC      BIC   logLik deviance df.resid 
##    445.2    463.2   -212.6    425.2       35 
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -0.95403 -0.21021 -0.00504  0.16007  0.43396 
## 
## Random effects:
##  Groups  Name        Variance Std.Dev.
##  obs_id  (Intercept) 0.2892   0.5378  
##  blockID (Intercept) 0.1755   0.4189  
## Number of obs: 45, groups:  obs_id, 45; blockID, 18
## 
## Fixed effects:
##                                 Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)                      3.28902    0.22578  14.567  &lt; 2e-16 ***
## site_sysBoyd_silage              0.06262    0.32769   0.191  0.84846    
## site_sysFuncke_grain             2.01960    0.44965   4.492 7.07e-06 ***
## site_sysStout_grain             -0.38915    0.42852  -0.908  0.36381    
## cc_trtnone                      -0.31789    0.26083  -1.219  0.22293    
## site_sysBoyd_silage:cc_trtnone   1.26342    0.44048   2.868  0.00413 ** 
## site_sysFuncke_grain:cc_trtnone  1.02944    0.49836   2.066  0.03886 *  
## site_sysStout_grain:cc_trtnone   0.74297    0.48961   1.517  0.12915    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) st_sB_ st_sF_ st_sS_ cc_trt s_B_:_ s_F_:_
## st_sysByd_s -0.450                                          
## st_sysFnck_ -0.502  0.225                                   
## st_sysStt_g -0.525  0.239  0.263                            
## cc_trtnone  -0.565  0.392  0.284  0.298                     
## st_sysBy_:_  0.335 -0.683 -0.168 -0.176 -0.592              
## st_sysFn_:_  0.296 -0.204 -0.628 -0.155 -0.524  0.310       
## st_sysSt_:_  0.301 -0.210 -0.151 -0.580 -0.533  0.316  0.279</code></pre>
<pre class="r"><code>summary(g1a)</code></pre>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: Negative Binomial(3.7588)  ( log )
## Formula: totseeds ~ site_sys * cc_trt + (1 | blockID)
##    Data: dat2
## 
##      AIC      BIC   logLik deviance df.resid 
##    445.4    463.5   -212.7    425.4       35 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -1.2879 -0.6244 -0.1260  0.4711  2.0199 
## 
## Random effects:
##  Groups  Name        Variance Std.Dev.
##  blockID (Intercept) 0.179    0.4231  
## Number of obs: 45, groups:  blockID, 18
## 
## Fixed effects:
##                                 Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)                      3.43950    0.22667  15.174  &lt; 2e-16 ***
## site_sysBoyd_silage             -0.01624    0.32432  -0.050  0.96005    
## site_sysFuncke_grain             1.88043    0.44272   4.247 2.16e-05 ***
## site_sysStout_grain             -0.45557    0.42093  -1.082  0.27912    
## cc_trtnone                      -0.32847    0.25796  -1.273  0.20290    
## site_sysBoyd_silage:cc_trtnone   1.35345    0.43192   3.134  0.00173 ** 
## site_sysFuncke_grain:cc_trtnone  1.03593    0.48511   2.135  0.03273 *  
## site_sysStout_grain:cc_trtnone   0.77414    0.47305   1.636  0.10174    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) st_sB_ st_sF_ st_sS_ cc_trt s_B_:_ s_F_:_
## st_sysByd_s -0.464                                          
## st_sysFnck_ -0.513  0.237                                   
## st_sysStt_g -0.518  0.249  0.265                            
## cc_trtnone  -0.574  0.445  0.295  0.298                     
## st_sysBy_:_  0.344 -0.694 -0.176 -0.180 -0.609              
## st_sysFn_:_  0.307 -0.237 -0.625 -0.158 -0.533  0.324       
## st_sysSt_:_  0.316 -0.243 -0.162 -0.564 -0.547  0.333  0.292</code></pre>
<pre class="r"><code>performance::compare_performance(p1b, g1a)</code></pre>
<pre><code>## # Comparison of Model Performance Indices
## 
## Model |     Type |    AIC |    BIC | R2_conditional | R2_marginal |  ICC | RMSE | SCORE_LOG | SCORE_SPHERICAL |   BF
## --------------------------------------------------------------------------------------------------------------------
## p1b   | glmerMod | 445.17 | 463.24 |           0.78 |        0.66 | 0.36 | 0.35 |     -2.82 |            0.14 |     
## g1a   | glmerMod | 445.44 | 463.50 |           0.81 |        0.67 | 0.42 | 0.90 |     -4.49 |            0.12 | 0.88</code></pre>
<p>Both these models have very similar AICs, and they also have very similar p-values which is reassuring, since our interpretation of the data won’t change depending on the model we choose.</p>
<p>In the end we decided to go with the Poisson-observation-level-random-effect model (named here <code>p1b</code>). If only because it is a little more straightforward than negative binomial models.</p>
